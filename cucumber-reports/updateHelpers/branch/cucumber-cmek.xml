<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<testsuite failures="1" name="cucumber.runtime.formatter.JUnitFormatter" skipped="0" tests="6" time="659.110761">
<testcase classname="BigQuery sink - Verification of GCS to BigQuery successful data transfer" name="Validate successful records transfer from GCS to BigQuery" time="126.781665">
<system-out><![CDATA[Given Open Datafusion Project to configure pipeline.........................passed
When Source is GCS..........................................................passed
When Sink is BigQuery.......................................................passed
Then Open GCS source properties.............................................passed
Then Enter the GCS source mandatory properties..............................passed
Then Validate "GCS" plugin properties.......................................passed
Then Close the GCS properties...............................................passed
Then Open BigQuery sink properties..........................................passed
Then Enter BigQuery property reference name.................................passed
Then Enter BigQuery property projectId "projectId"..........................passed
Then Enter BigQuery property datasetProjectId "projectId"...................passed
Then Enter BigQuery property dataset "dataset"..............................passed
Then Enter BigQuery sink property table name................................passed
Then Enter BiqQuery property encryption key name "cmekBQ" if cmek is enabled.passed
Then Toggle BigQuery sink property truncateTable to true....................passed
Then Toggle BigQuery sink property updateTableSchema to true................passed
Then Validate "BigQuery" plugin properties..................................passed
Then Close the BigQuery properties..........................................passed
Then Connect source as "GCS" and sink as "BigQuery" to establish connection.passed
Then Save the pipeline......................................................passed
Then Preview and run the pipeline...........................................passed
Then Verify the preview of pipeline is "success"............................passed
Then Close the preview......................................................passed
Then Deploy the pipeline....................................................passed
Then Run the Pipeline in Runtime............................................passed
Then Wait till pipeline is in running state.................................passed
Then Open and capture logs..................................................passed
Then Verify the pipeline status is "Succeeded"..............................passed
Then Get count of no of records transferred to target BigQuery Table........passed
Then Validate the cmek key "cmekBQ" of target BigQuery table if cmek is enabled.passed
]]></system-out>
</testcase>
<testcase classname="BigQuery source - Verification of BigQuery to GCS successful data transfer" name="Validate successful records transfer from BigQuery to GCS" time="133.061683">
<system-out><![CDATA[Given Open Datafusion Project to configure pipeline.........................passed
When Source is BigQuery.....................................................passed
When Sink is GCS............................................................passed
Then Open BigQuery source properties........................................passed
Then Enter BigQuery property reference name.................................passed
Then Enter BigQuery property projectId "projectId"..........................passed
Then Enter BigQuery property datasetProjectId "projectId"...................passed
Then Enter BigQuery property dataset "dataset"..............................passed
Then Enter BigQuery source property table name..............................passed
Then Enter BiqQuery property encryption key name "cmekBQ" if cmek is enabled.passed
Then Validate output schema with expectedSchema "bqSourceSchema"............passed
Then Validate "BigQuery" plugin properties..................................passed
Then Close the BigQuery properties..........................................passed
Then Open GCS sink properties...............................................passed
Then Enter the GCS sink mandatory properties................................passed
Then Validate "GCS" plugin properties.......................................passed
Then Close the GCS properties...............................................passed
Then Connect source as "BigQuery" and sink as "GCS" to establish connection.passed
Then Save the pipeline......................................................passed
Then Preview and run the pipeline...........................................passed
Then Verify the preview of pipeline is "success"............................passed
Then Click on preview data for GCS sink.....................................passed
Then Verify preview output schema matches the outputSchema captured in properties.passed
Then Close the preview data.................................................passed
Then Deploy the pipeline....................................................passed
Then Run the Pipeline in Runtime............................................passed
Then Wait till pipeline is in running state.................................passed
Then Open and capture logs..................................................passed
Then Verify the pipeline status is "Succeeded"..............................passed
Then Verify data is transferred to target GCS bucket........................passed
]]></system-out>
</testcase>
<testcase classname="BigQuery source - Verification of BigQuery to Multiple sinks successful data transfer" name="Validate successful records transfer from BigQuery to multiple sinks (GCS, BigQuery and PubSub)" time="36.571536">
<failure message="org.openqa.selenium.NoSuchElementException: no such element: Unable to locate element: {&quot;method&quot;:&quot;xpath&quot;,&quot;selector&quot;:&quot;//div[@title='BigQuery']/ancestor::div[contains(@data-cy,'plugin-node-BigQuery') and @data-type='batchsource']//*[contains(@data-cy,'plugin-endpoint-BigQuery')]&quot;}&#10;  (Session info: headless chrome=92.0.4515.159)&#10;For documentation on this error, please visit: https://selenium.dev/exceptions/#no_such_element&#10;Build info: version: '4.0.0-rc-1', revision: 'bc5511cbda'&#10;System info: host: 'runner-deployment-build-e2e-cdapio-65d7f4cfcc-rnptk', ip: '10.116.13.11', os.name: 'Linux', os.arch: 'amd64', os.version: '5.4.144+', java.version: '1.8.0_292'&#10;Driver info: org.openqa.selenium.chrome.ChromeDriver&#10;Command: [9cfb12374e98a7cca0753f07674ccb52, findElement {using=xpath, value=//div[@title='BigQuery']/ancestor::div[contains(@data-cy,'plugin-node-BigQuery') and @data-type='batchsource']//*[contains(@data-cy,'plugin-endpoint-BigQuery')]}]&#10;Capabilities {acceptInsecureCerts: false, browserName: chrome, browserVersion: 92.0.4515.159, chrome: {chromedriverVersion: 92.0.4515.107 (87a818b10553..., userDataDir: /tmp/.com.google.Chrome.9jZvc6}, goog:chromeOptions: {debuggerAddress: localhost:42017}, javascriptEnabled: true, networkConnectionEnabled: false, pageLoadStrategy: normal, platform: LINUX, platformName: LINUX, proxy: Proxy(), se:cdp: ws://localhost:42017/devtoo..., se:cdpVersion: 92.0.4515.159, setWindowRect: true, strictFileInteractability: false, timeouts: {implicit: 0, pageLoad: 300000, script: 30000}, unhandledPromptBehavior: dismiss and notify, webauthn:extension:credBlob: true, webauthn:extension:largeBlob: true, webauthn:virtualAuthenticators: true}&#10;Session ID: 9cfb12374e98a7cca0753f07674ccb52&#10;&#9;at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)&#10;&#9;at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)&#10;&#9;at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&#10;&#9;at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&#10;&#9;at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.createException(W3CHttpResponseCodec.java:200)&#10;&#9;at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:133)&#10;&#9;at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:53)&#10;&#9;at org.openqa.selenium.remote.HttpCommandExecutor.execute(HttpCommandExecutor.java:184)&#10;&#9;at org.openqa.selenium.remote.service.DriverCommandExecutor.invokeExecute(DriverCommandExecutor.java:164)&#10;&#9;at org.openqa.selenium.remote.service.DriverCommandExecutor.execute(DriverCommandExecutor.java:139)&#10;&#9;at org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:547)&#10;&#9;at org.openqa.selenium.remote.ElementLocation$ElementFinder$2.findElement(ElementLocation.java:162)&#10;&#9;at org.openqa.selenium.remote.ElementLocation.findElement(ElementLocation.java:60)&#10;&#9;at org.openqa.selenium.remote.RemoteWebDriver.findElement(RemoteWebDriver.java:381)&#10;&#9;at org.openqa.selenium.remote.RemoteWebDriver.findElement(RemoteWebDriver.java:373)&#10;&#9;at io.cdap.e2e.pages.locators.CdfStudioLocators.sourceEndpointWithTitle(CdfStudioLocators.java:133)&#10;&#9;at io.cdap.e2e.utils.CdfHelper.connectSourceAndSinkWithTitles(CdfHelper.java:147)&#10;&#9;at stepsdesign.PipelineSteps.connectSourceAsHavingTitleAndSinkAsHavingTitleToEstablishConnection(PipelineSteps.java:98)&#10;&#9;at âœ½.Connect source as &quot;BigQuery&quot; having title &quot;BigQuery&quot; and sink1 as &quot;GCS&quot; having title &quot;GCS&quot; to establish connection(file:src/e2e-test/features/bigquery/source/BigQueryToMultipleSinks.feature:12)&#10;"><![CDATA[Given Open Datafusion Project to configure pipeline.........................passed
And Wait for page to render properly........................................passed
When Source is BigQuery.....................................................passed
When Sink is GCS............................................................passed
Then Connect source as "BigQuery" having title "BigQuery" and sink1 as "GCS" having title "GCS" to establish connection.failed
When Sink is BigQuery.......................................................skipped
Then Connect source as "BigQuery" having title "BigQuery" and sink2 as "BigQuery" having title "BigQuery2" to establish connection.skipped
When Sink is PubSub.........................................................skipped
Then Connect source as "BigQuery" having title "BigQuery" and sink3 as "GooglePublisher" having title "Pub/Sub" to establish connection.skipped
Then Open BigQuery source properties........................................skipped
Then Enter the BigQuery source mandatory properties.........................skipped
Then Validate "BigQuery" plugin properties..................................skipped
Then Close the BigQuery properties..........................................skipped
Then Open GCS sink properties...............................................skipped
Then Enter the GCS sink mandatory properties................................skipped
Then Enter GCS property encryption key name "cmekGCS" if cmek is enabled....skipped
Then Validate "GCS" plugin properties.......................................skipped
Then Close the GCS properties...............................................skipped
Then Open BigQuery sink properties..........................................skipped
Then Enter the BigQuery sink mandatory properties...........................skipped
Then Enter BiqQuery property encryption key name "cmekBQ" if cmek is enabled.skipped
Then Validate "BigQuery" plugin properties..................................skipped
Then Close the BigQuery properties..........................................skipped
Then Open the PubSub sink properties........................................skipped
Then Enter the PubSub sink mandatory properties.............................skipped
Then Enter PubSub sink property encryption key name "cmekPubSub" if cmek is enabled.skipped
Then Validate "PubSub" plugin properties....................................skipped
Then Close the PubSub properties............................................skipped
Then Save the pipeline......................................................skipped
Then Preview and run the pipeline...........................................skipped
Then Verify the preview of pipeline is "success"............................skipped
Then Close the preview......................................................skipped
Then Deploy the pipeline....................................................skipped
Then Run the Pipeline in Runtime............................................skipped
Then Wait till pipeline is in running state.................................skipped
Then Open and capture logs..................................................skipped
Then Verify the pipeline status is "Succeeded"..............................skipped
Then Verify data is transferred to target GCS bucket........................skipped
Then Get count of no of records transferred to target BigQuery Table........skipped
Then Validate the cmek key "cmekGCS" of target GCS bucket if cmek is enabled.skipped
Then Validate the cmek key "cmekBQ" of target BigQuery table if cmek is enabled.skipped
Then Validate the cmek key "cmekPubSub" of target PubSub topic if cmek is enabled.skipped

StackTrace:
org.openqa.selenium.NoSuchElementException: no such element: Unable to locate element: {"method":"xpath","selector":"//div[@title='BigQuery']/ancestor::div[contains(@data-cy,'plugin-node-BigQuery') and @data-type='batchsource']//*[contains(@data-cy,'plugin-endpoint-BigQuery')]"}
  (Session info: headless chrome=92.0.4515.159)
For documentation on this error, please visit: https://selenium.dev/exceptions/#no_such_element
Build info: version: '4.0.0-rc-1', revision: 'bc5511cbda'
System info: host: 'runner-deployment-build-e2e-cdapio-65d7f4cfcc-rnptk', ip: '10.116.13.11', os.name: 'Linux', os.arch: 'amd64', os.version: '5.4.144+', java.version: '1.8.0_292'
Driver info: org.openqa.selenium.chrome.ChromeDriver
Command: [9cfb12374e98a7cca0753f07674ccb52, findElement {using=xpath, value=//div[@title='BigQuery']/ancestor::div[contains(@data-cy,'plugin-node-BigQuery') and @data-type='batchsource']//*[contains(@data-cy,'plugin-endpoint-BigQuery')]}]
Capabilities {acceptInsecureCerts: false, browserName: chrome, browserVersion: 92.0.4515.159, chrome: {chromedriverVersion: 92.0.4515.107 (87a818b10553..., userDataDir: /tmp/.com.google.Chrome.9jZvc6}, goog:chromeOptions: {debuggerAddress: localhost:42017}, javascriptEnabled: true, networkConnectionEnabled: false, pageLoadStrategy: normal, platform: LINUX, platformName: LINUX, proxy: Proxy(), se:cdp: ws://localhost:42017/devtoo..., se:cdpVersion: 92.0.4515.159, setWindowRect: true, strictFileInteractability: false, timeouts: {implicit: 0, pageLoad: 300000, script: 30000}, unhandledPromptBehavior: dismiss and notify, webauthn:extension:credBlob: true, webauthn:extension:largeBlob: true, webauthn:virtualAuthenticators: true}
Session ID: 9cfb12374e98a7cca0753f07674ccb52
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.createException(W3CHttpResponseCodec.java:200)
	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:133)
	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:53)
	at org.openqa.selenium.remote.HttpCommandExecutor.execute(HttpCommandExecutor.java:184)
	at org.openqa.selenium.remote.service.DriverCommandExecutor.invokeExecute(DriverCommandExecutor.java:164)
	at org.openqa.selenium.remote.service.DriverCommandExecutor.execute(DriverCommandExecutor.java:139)
	at org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:547)
	at org.openqa.selenium.remote.ElementLocation$ElementFinder$2.findElement(ElementLocation.java:162)
	at org.openqa.selenium.remote.ElementLocation.findElement(ElementLocation.java:60)
	at org.openqa.selenium.remote.RemoteWebDriver.findElement(RemoteWebDriver.java:381)
	at org.openqa.selenium.remote.RemoteWebDriver.findElement(RemoteWebDriver.java:373)
	at io.cdap.e2e.pages.locators.CdfStudioLocators.sourceEndpointWithTitle(CdfStudioLocators.java:133)
	at io.cdap.e2e.utils.CdfHelper.connectSourceAndSinkWithTitles(CdfHelper.java:147)
	at stepsdesign.PipelineSteps.connectSourceAsHavingTitleAndSinkAsHavingTitleToEstablishConnection(PipelineSteps.java:98)
	at âœ½.Connect source as "BigQuery" having title "BigQuery" and sink1 as "GCS" having title "GCS" to establish connection(file:src/e2e-test/features/bigquery/source/BigQueryToMultipleSinks.feature:12)
]]></failure>
</testcase>
<testcase classname="GCS sink - Verification of GCS Sink plugin" name="To verify data is getting transferred successfully from BigQuery to GCS" time="135.183594">
<system-out><![CDATA[Given Open Datafusion Project to configure pipeline.........................passed
When Source is BigQuery.....................................................passed
When Sink is GCS............................................................passed
Then Connect source as "BigQuery" and sink as "GCS" to establish connection.passed
Then Open BigQuery source properties........................................passed
Then Enter the BigQuery source mandatory properties.........................passed
Then Validate "BigQuery" plugin properties..................................passed
Then Close the BigQuery properties..........................................passed
Then Open GCS sink properties...............................................passed
Then Enter GCS property projectId and reference name........................passed
Then Enter GCS sink property path...........................................passed
Then Select GCS property format "csv".......................................passed
Then Enter GCS property encryption key name "cmekGCS" if cmek is enabled....passed
Then Validate "GCS" plugin properties.......................................passed
Then Close the GCS properties...............................................passed
Then Save the pipeline......................................................passed
Then Preview and run the pipeline...........................................passed
Then Verify the preview of pipeline is "success"............................passed
Then Close the preview......................................................passed
Then Deploy the pipeline....................................................passed
Then Run the Pipeline in Runtime............................................passed
Then Wait till pipeline is in running state.................................passed
Then Open and capture logs..................................................passed
Then Verify the pipeline status is "Succeeded"..............................passed
Then Verify data is transferred to target GCS bucket........................passed
Then Validate the cmek key "cmekGCS" of target GCS bucket if cmek is enabled.passed
]]></system-out>
</testcase>
<testcase classname="PubSub-Sink - Verification of BigQuery to PubSub successful data transfer" name="To verify data is getting transferred from BigQuery to PubSub successfully" time="136.473627">
<system-out><![CDATA[Given Open Datafusion Project to configure pipeline.........................passed
When Source is BigQuery.....................................................passed
When Sink is PubSub.........................................................passed
Then Connect source as "BigQuery" and sink as "GooglePublisher" to establish connection.passed
Then Open BigQuery source properties........................................passed
Then Enter the BigQuery source mandatory properties.........................passed
Then Validate "BigQuery" plugin properties..................................passed
Then Close the BigQuery properties..........................................passed
Then Open the PubSub sink properties........................................passed
Then Enter PubSub property projectId "projectId"............................passed
Then Enter PubSub property reference name...................................passed
Then Enter PubSub sink property topic name..................................passed
Then Select PubSub property format "csv"....................................passed
Then Enter PubSub sink property encryption key name "cmekPubSub" if cmek is enabled.passed
Then Enter PubSub sink property MaximumBatchCount "pubSubMaximumBatchCount".passed
Then Enter PubSub sink property MaximumBatchSize "pubSubMaximumBatchSize"...passed
Then Enter PubSub sink property PublishDelayThreshold "pubSubPublishDelayThreshold".passed
Then Enter PubSub sink property RetryTimeOut "pubSubRetryTimeOut"...........passed
Then Enter PubSub sink property ErrorThreshold "pubSubErrorThreshold".......passed
Then Validate "PubSub" plugin properties....................................passed
Then Close the PubSub properties............................................passed
Then Save the pipeline......................................................passed
Then Preview and run the pipeline...........................................passed
Then Verify the preview of pipeline is "success"............................passed
Then Close the preview......................................................passed
Then Deploy the pipeline....................................................passed
Then Run the Pipeline in Runtime............................................passed
Then Wait till pipeline is in running state.................................passed
Then Verify the pipeline status is "Succeeded"..............................passed
Then Validate OUT record count is equal to IN record count..................passed
Then Open and capture logs..................................................passed
Then Validate the cmek key "cmekPubSub" of target PubSub topic if cmek is enabled.passed
]]></system-out>
</testcase>
<testcase classname="PubSub-Sink - Verification of GCS to PubSub successful data transfer" name="To verify data is getting transferred from GCS to PubSub successfully" time="91.038656">
<system-out><![CDATA[Given Open Datafusion Project to configure pipeline.........................passed
When Source is GCS..........................................................passed
When Sink is PubSub.........................................................passed
Then Open GCS source properties.............................................passed
Then Enter the GCS source mandatory properties..............................passed
Then Validate "GCS" plugin properties.......................................passed
Then Close the GCS properties...............................................passed
Then Open the PubSub sink properties........................................passed
Then Enter PubSub property projectId "projectId"............................passed
Then Enter PubSub property reference name...................................passed
Then Enter PubSub sink property topic name..................................passed
Then Select PubSub property format "csv"....................................passed
Then Enter PubSub sink property encryption key name "cmekPubSub" if cmek is enabled.passed
Then Enter PubSub sink property MaximumBatchCount "pubSubMaximumBatchCount".passed
Then Enter PubSub sink property MaximumBatchSize "pubSubMaximumBatchSize"...passed
Then Enter PubSub sink property PublishDelayThreshold "pubSubPublishDelayThreshold".passed
Then Enter PubSub sink property RetryTimeOut "pubSubRetryTimeOut"...........passed
Then Enter PubSub sink property ErrorThreshold "pubSubErrorThreshold".......passed
Then Validate "PubSub" plugin properties....................................passed
Then Close the PubSub properties............................................passed
Then Connect source as "GCS" and sink as "GooglePublisher" to establish connection.passed
Then Save the pipeline......................................................passed
Then Preview and run the pipeline...........................................passed
Then Verify the preview of pipeline is "success"............................passed
Then Close the preview......................................................passed
Then Deploy the pipeline....................................................passed
Then Run the Pipeline in Runtime............................................passed
Then Wait till pipeline is in running state.................................passed
Then Verify the pipeline status is "Succeeded"..............................passed
Then Validate OUT record count is equal to IN record count..................passed
Then Open and capture logs..................................................passed
Then Validate the cmek key "cmekPubSub" of target PubSub topic if cmek is enabled.passed
]]></system-out>
</testcase>
</testsuite>
